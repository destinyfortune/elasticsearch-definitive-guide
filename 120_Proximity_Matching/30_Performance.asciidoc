[role="pagebreak-before"]
=== 性能优化

短语查询和邻近查询都比简单的 `query` 查询在性能上更昂贵 ((("proximity matching", "improving performance")))((("phrase matching", "improving performance")))。
一个 `match` 查询仅仅是看词条是否存在于倒排索引中， 而一个 `match_phrase` 查询是必须计算并比较多个可能重复词条的位置。

http://people.apache.org/~mikemccand/lucenebench/[Lucene nightly benchmarks]表明一个简单的 `term` 查询比一个短语查询大约快10倍， 比邻近查询(有 `slop` 的短语查询)大约快20倍。
当然， 这个代价指的是在搜索时而不是在索引时的。

[TIP]
==================================================

通常短语查询的额外代价并没有刚刚提及的这些数字这么恐怖。 事实上， 性能上的差距只是证明一个简单的 `term` 查询多快。 在标准全文数据的短语查询通常在几毫秒内完成， 因此在实际上都是完全可用的，即使是在一个繁忙的集群上。

在某些特定病理案例下， 短语查询可能代价高昂， 但是这是不常有的。 一个典型例子就是DNA序列， 在序列里很多很多同样的词条在很多位置重复出现。 在这里使用高 `slop` 值会到导致位置计算的大量增加。


==================================================

那么我们应该如何限制短语查询和邻近近查询的性能消耗呢？ 一种有用的方法就是减少需要通过短语查询检查的文档总数。

[[rescore-api]]
==== 结果分数重计算

在<<proximity-relevance,the preceding section>>， 我们讨论了而使用邻近查询来调整相关度， 而不是使用它将文档从结果列表中添加或者排除。 ((("relevance scores", "rescoring results for top-N documents with proximity query")))
一个查询可能会匹配成千上万的结果， 但我们的用户很可能只对结果的前几页感兴趣。

一个简单的 `match` 查询已经通过排序把包含所有含有搜索词条的文档放在结果列表的前面了。 事实上， 我们只是想要对这些_前面的结果_重新排序来给同时匹配了短语查询的文档一个额外的相关度。

`search` API刚好通过 _分数重计算_ 支持这个功能。 ((("rescoring")))分数重计算这个阶段允许你应用一个代价更高的评分算法--比如 `phrase` 查询--只是为了从每个分片中获得前 `K` 个结果。 然后会根据它们的最新评分重新排序。

该请求如下：

[source,js]
--------------------------------------------------
GET /my_index/my_type/_search
{
    "query": {
        "match": {  <1>
            "title": {
                "query":                "quick brown fox",
                "minimum_should_match": "30%"
            }
        }
    },
    "rescore": {
        "window_size": 50, <2>
        "query": {         <3>
            "rescore_query": {
                "match_phrase": {
                    "title": {
                        "query": "quick brown fox",
                        "slop":  50
                    }
                }
            }
        }
    }
}
--------------------------------------------------
// SENSE: 120_Proximity_Matching/30_Performance.json

<1> `match` 查询决定哪些结果被包含在最终结果集中， 结果通过TF/IDF排序。((("window_size parameter")))
<2> `window_size` 就是每一分片中要重新打分的结果数量。
<3> 目前唯一支持的重新打分算法就是另一个查询， 但是以后会有计划增加更多的算法。

